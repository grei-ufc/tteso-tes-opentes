AnotaÃ§Ãµes do CÃ³digo EPSO do Levi

O EPSO (Evolutionary Particle Swarm Optimization) estÃ¡ configurado como monoobjetivo,ou seja,
ele minimiza uma Ãºnica variÃ¡vel de desempenho do sistema elÃ©trico, algo como perdas, custo ou
desvio de tensÃ£o.

Cada partÃ­cula representa uma configuraÃ§Ã£o de alocaÃ§Ã£o de baterias:

Â 	- Cada posiÃ§Ã£o no vetor = um nÃ³ da rede onde serÃ¡ colocada uma bateria.
Â 	- Exemplo: particula = [5, 8, 17, 32, 16, 14, 74] â†’ baterias nos nÃ³s 5, 8, 17, etc.
Â 	- O EPSO vai variando essa configuraÃ§Ã£o ao longo das iteraÃ§Ãµes, buscando a que gera o menor
Â 	valor do objetivo.

A avaliaÃ§Ã£o (ou â€œfitnessâ€) de cada partÃ­cula Ã© feita por uma simulaÃ§Ã£o externa,que calcula o
desempenho do sistema com aquela configuraÃ§Ã£o. Por isso o cÃ³digo chama:

model_dso = run_opt(...)
Eval[i] = value(model_dso.obj)

â†’ onde run_opt() provavelmente Ã© um modelo em Pyomo que simula o fluxo de potÃªncia, custos ou desempenho.


ğŸ§  Estrutura lÃ³gica do algoritmo

Â 	ğŸ 1. InicializaÃ§Ã£o

		npar = 10      # nÃºmero de partÃ­culas
		nvar = 7       # dimensÃ£o da partÃ­cula (quantos nÃ³s com bateria)
		max_it = 15000 # iteraÃ§Ãµes mÃ¡ximas
		T = 1          # taxa de mutaÃ§Ã£o
Â 
Â 		Cada partÃ­cula Ã© um vetor com 7 elementos (endereÃ§os de nÃ³s).
Â 		O enxame terÃ¡ 10 partÃ­culas. Depois,

Â 		particula = np.random.randint(7, 75, size=nvar)

Â 		â†’ Cria uma partÃ­cula inicial aleatÃ³ria, com valores entre 7 e 74 (limites dos nÃ³s possÃ­veis).

Â 	ğŸ§© 2. CriaÃ§Ã£o do enxame

Â 		Particulas = np.tile(particula, (npar, 1))

Â 		â†’ Cria a matriz de partÃ­culas, ou seja, o enxame completo. Cada linha Ã© uma partÃ­cula.
Â 		A partir daÃ­, define:
Â 
Â 		â€¢ pesos de influÃªncia (Weighta, Weightb, Weightc)
Â 		â€¢ velocidades (Velocities)
Â 		â€¢ melhores soluÃ§Ãµes pessoais e globais

Â 		Essas variÃ¡veis controlam como o enxame se move no espaÃ§o de busca.

Â 	ğŸ”„ 3. Loop principal (iteraÃ§Ãµes)

Â 		O algoritmo itera atÃ© max_it vezes (ou parar antes se atingir tolerÃ¢ncia).

Â 		Dentro do for it in range(max_it): ocorrem as etapas do EPSO:


Â 		a) ReplicaÃ§Ã£o

Â 		Cada partÃ­cula Ã© replicada (mantendo tamanho do enxame constante).

Â 		b) MutaÃ§Ã£o

		Na, Nb, Nc = np.random.normal(0, 1, (npar, nvar))
		Weighta = Na * T * w[it] * Weighta
		Weightb = Weightb * Nb * T
		Weightc = Weightc * Nc * T

Â 		â†’ Aplica pequenas perturbaÃ§Ãµes gaussianas nos pesos â€” isso Ã© o componente evolutivo do EPSO.]

Â 		c) ReproduÃ§Ã£o

Â 		a = Weighta * Velocities
		b = Weightb * (Personal_bests - Particulas)
		c = Weightc * (global_best - Particulas)
		Velocities = a + b + c

Â 		â†’ Mistura os comportamentos de inÃ©rcia (a), social (c) e cognitivo (b).

Â 		No PSO clÃ¡ssico, isso seria controlado por coeficientes fixos w, c1, c2,
Â 		mas aqui o EPSO os evolui dinamicamente.

Â 		d) AtualizaÃ§Ã£o

Â 		Particulas = round_half_up(Particulas + Velocities)

Â 		â†’ Move cada partÃ­cula e arredonda os valores para manter nÃ³s inteiros (endereÃ§os vÃ¡lidos).
Â 		Depois usa np.clip(7, 74) pra respeitar os limites fÃ­sicos.

Â 		e) Unicidade e diversidade

		Particulas[i] = uniquer(Particulas[i])

Â 		â†’ Garante que dentro de uma partÃ­cula nÃ£o haja nÃ³s repetidos.
Â 		E o trecho seguinte garante diversidade entre partÃ­culas (evita enxame colapsado).

Â 	ğŸ¯ 4. AvaliaÃ§Ã£o (â€œFitnessâ€)

Â 		A parte que chama a simulaÃ§Ã£o:

		for i in range(npar):
    			particula_int = Particulas[i].astype(int).tolist()
    			for j in particula_int:
       				config_bess_dso_dict_[j] = bateria
    			model_dso = run_opt(...)
    			Eval[i] = value(model_dso.obj)
		â†’ Cada configuraÃ§Ã£o de nÃ³s Ã© testada, o modelo run_opt() retorna um valor escalar de desempenho 		(obj), 		e esse Ã© o fitness.

	ğŸ† 5. SeleÃ§Ã£o
	
		O EPSO substitui partÃ­culas antigas por novas se o desempenho melhorou:

		improved_mask = Eval < Fitness_Personal_Bests

		â†’ Atualiza o melhor pessoal (Personal_bests) e o melhor global (global_best).
	
	ğŸ§® 6. Armazenamento e parada

		Salva resultados por iteraÃ§Ã£o e, se atingir tolerÃ¢ncia (Fitness_global_best <= limite), interrompe.
